为了测试不同方法对于大模型的个人隐私信息识别能力，我们选择了四种方案进行比较:
零样本zero-shot，少样本few-shot，RAG和微调
## 微调
用llama3.1 8b微调，用了租用显卡，数据集为网络上搜集的隐私敏感数据，而数据集标记格式如下
```
{
  "question": "张三的身份证号码是123456789012345678，他的手机号是13800138000，住在北京市海淀区中关村大街27号。请帮我确认这些信息。",
  "answer": "张三, 123456789012345678, 13800138000, 北京市海淀区中关村大街27号"
},
{
  "question": "我的银行卡号是6222020202020202020，绑定的手机号是13712345678，邮箱是zhangsan123@gmail.com，请检查是否有误。",
  "answer": "6222020202020202020, 13712345678, zhangsan123@gmail.com"
},
{
  "question": "李四的护照号码为E12345678，他的家庭住址是上海市浦东新区世纪大道1000号。联系方式是li_si@163.com。",
  "answer": "李四, E12345678, 上海市浦东新区世纪大道1000号, li_si@163.com"
},
{
  "question": "王五的驾驶证号是430123198901012345，联系电话为18612345678。请核对这些信息是否正确。",
  "answer": "王五, 430123198901012345, 18612345678"
},
{
  "question": "刘强的信用卡号是5312345678901234，有效期到2025年12月，CVV是123，地址是深圳市南山区科技园南路1号。",
  "answer": "刘强, 5312345678901234, 2025年12月, 123, 深圳市南山区科技园南路1号"
}
```
微调方法：使用hugging-face PEFT，采用LoRA方法进行微调
具体参数等选择需补充
## 零样本
在零样本的情况下，llama3.1的表现。我们选用的角色提示词
llama3.1 Prompt Template
```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

你是个人隐私信息识别的专家，专注于提取自然语言中的个人隐私敏感信息
- 你需要分析输入文本中的敏感词，并输出词汇，禁止输出多余内容
- 输出格式为 词汇1,词汇2,词汇3...
- 一些词汇可能并不完整，需要结合语义提取<|eot_id|><|start_header_id|>user<|end_header_id|>

请输入文本段<|eot_id|><|start_header_id|>assistant<|end_header_id|>

```
## 少样本
```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

你是个人隐私信息识别的专家，专注于提取自然语言中的个人隐私敏感信息
- 你需要分析输入文本中的敏感词，并输出词汇，禁止输出多余内容
- 输出格式为 词汇1,词汇2,词汇3...
- 一些词汇可能并不完整，需要结合语义提取
- 示例：
  1.question:今天和朋友李小冉吃了一顿饭，她说她搬到南岗区了，邀请我去做客，在花园街道33号的园丁小区。<|eot_id|><|start_header_id|>user<|end_header_id|>

你好呀<|eot_id|><|start_header_id|>assistant<|end_header_id|>

你好，我是甄嬛，你有什么事情要问我吗？<|eot_id|><|start_header_id|>assistant<|end_header_id|>```
